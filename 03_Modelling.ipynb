{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/petr-ngn/CNN_Real_Estate_Offices_Amenities_Listing/blob/main/03_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing and importing relevant libraries"
      ],
      "metadata": {
        "id": "2oMo5L0IbIMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "!pip install visualkeras"
      ],
      "metadata": {
        "id": "UDje2-0GaiBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefe8043-a10e-4ba3-93ac-9fbe2b848063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.9.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.51.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (5.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (5.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.2)\n",
            "Installing collected packages: kt-legacy, jedi, keras-tuner\n",
            "Successfully installed jedi-0.18.2 keras-tuner-1.1.3 kt-legacy-1.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from visualkeras) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from visualkeras) (1.21.6)\n",
            "Collecting aggdraw>=1.3.11\n",
            "  Downloading aggdraw-1.3.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (992 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m992.2/992.2 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.15 visualkeras-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV_zlvL-aWvx"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.data import AUTOTUNE\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.backend import epsilon\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.math import square, maximum, reduce_mean, sqrt, reduce_sum\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D, BatchNormalization, Lambda\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting the Google Drive"
      ],
      "metadata": {
        "id": "LuXPpyIybOcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "l_WtyCxcaf7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2914da3-f77d-48db-c742-6f775c9dca26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing a costume created module by Petr Nguyen"
      ],
      "metadata": {
        "id": "3jsCpVLmbM_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/drive/MyDrive/Agile_ML/src_PN')"
      ],
      "metadata": {
        "id": "FusnZfYZayA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PN_functions as PN"
      ],
      "metadata": {
        "id": "nELE748Day6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Agile_ML'\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "7TaRJT8Qa2Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIrXc8TtaWvy"
      },
      "outputs": [],
      "source": [
        "#Parameter initialization\n",
        "random_seed = 123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_YBXS1KaWvz"
      },
      "outputs": [],
      "source": [
        "train_imgs, train_labels = PN.read_pairs('train')\n",
        "valid_imgs, valid_labels = PN.read_pairs('valid')\n",
        "test_imgs, test_labels = PN.read_pairs('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyCnLsdGaWv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a280c8cc-4a9d-4390-a06b-5a8be54bb42f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4050\n",
            "1250\n",
            "1250\n"
          ]
        }
      ],
      "source": [
        "print(f'number of pairs in training set: {len(train_imgs)}')\n",
        "print(f'number of pairs in validation set: {len(valid_imgs)}')\n",
        "print(f'number of pairs in test set: {len(test_imgs)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzNewynzaWv1"
      },
      "outputs": [],
      "source": [
        "train_tf = PN.tf_data_processing_pipeline(train_imgs, train_labels)\n",
        "valid_tf = PN.tf_data_processing_pipeline(valid_imgs, valid_labels)\n",
        "test_tf = PN.tf_data_processing_pipeline(test_imgs, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJAvn6R3aWv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267df82b-01bc-4227-f75a-c87595b3fc51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "405\n",
            "125\n",
            "530\n",
            "125\n"
          ]
        }
      ],
      "source": [
        "print('training set:', tf.data.experimental.cardinality(train_tf).numpy())\n",
        "print('validation set:', tf.data.experimental.cardinality(valid_tf).numpy())\n",
        "print('test set:', tf.data.experimental.cardinality(test_tf).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1hOUZPxaWv2"
      },
      "outputs": [],
      "source": [
        "#Function for calculation an Euclidean distance between the two feature vectors\n",
        "def euclidean_distance(vectors):\n",
        "\n",
        "    x, y = vectors\n",
        "    sum_square = reduce_sum(square(x - y), axis = 1, keepdims = True)\n",
        "\n",
        "    return sqrt(maximum(sum_square, epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for a calculation of a contrastive loss\n",
        "def contrastive_loss(margin = 1):\n",
        "\n",
        "    def contrastive__loss(y_true, y_pred):\n",
        "\n",
        "        square_pred = tf.math.square(y_pred)\n",
        "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "        return tf.math.reduce_mean(\n",
        "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "        )\n",
        "\n",
        "    return contrastive__loss"
      ],
      "metadata": {
        "id": "u-Qc_4rHHZWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yc9UouxxaWv2"
      },
      "outputs": [],
      "source": [
        "def model_building(hp):\n",
        "  \n",
        "    #Input layer\n",
        "    inputs = Input(shape = (224, 224, 3), name = 'input_layer')\n",
        "    x = inputs\n",
        "\n",
        "  \n",
        "        #Tuning the number of convolution's output filters \n",
        "        #Within each block, perform 2 convolutions and batch normalization\n",
        "        #Tuning the number of convolution's output filters\n",
        "    for i in range(hp.Int('conv_blocks', min_value = 3, max_value = 5, default = 3)):\n",
        "    \n",
        "    #Tuning the number of convolution's output filters\n",
        "      filters = hp.Int('filters_' + str(i), min_value = 32,\n",
        "                     max_value = 256, step = 32) \n",
        "    \n",
        "      for _ in range(2):\n",
        "\n",
        "        x = Conv2D(filters, kernel_size=(3, 3), padding = 'same',\n",
        "                 activation = 'relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "    #Tuning the pooling type in the convolutional block\n",
        "      if hp.Choice('pooling_' + str(i), ['avg', 'max']) == 'max':\n",
        "          x = MaxPooling2D(name = 'maxpooling_'+str(i))(x)\n",
        "      else:\n",
        "          x = AveragePooling2D(name = 'avgpooling_'+str(i))(x)\n",
        "\n",
        "      x = Dropout((hp.Float('dropout_' + str(i), 0, 0.5, step = 0.05, default = 0.5)))(x)\n",
        "\n",
        "    x = GlobalAveragePooling2D(name = 'globavgpool_01')(x)\n",
        "    #Flatten the output\n",
        "    x = Flatten(name = 'flatten_layer')(x)\n",
        "    #Tuning the number of units in the dense layer\n",
        "    x = Dense(hp.Int('Dense units' ,min_value = 50, max_value = 100, step = 10, default = 50), name = 'dense_01', activation='relu')(x)\n",
        "    #Tuning the dropout rate in the dropout layer - the final feature vector layer\n",
        "    feature_layer = Dropout(hp.Float('dropout_final', 0, 0.5, step = 0.05, default = 0.5), name = 'feature_layer', seed = 123)(x)\n",
        "    #Mapping a embedding model\n",
        "    embedding_network = Model(inputs, feature_layer, name = 'SNN')\n",
        "    #Setting an input layer for the image pairs\n",
        "    input_1 = Input((224, 224, 3), name = 'left_tower')\n",
        "    input_2 = Input((224, 224, 3), name = 'right_tower')\n",
        "    tower_1 = embedding_network(input_1)\n",
        "    tower_2 = embedding_network(input_2)\n",
        "    #Layers for calculation of the Euclidean distance between the two feature vectors, with further normalization\n",
        "    merge_layer = Lambda(euclidean_distance, name = 'lambda_layer')([tower_1, tower_2])\n",
        "    normal_layer = BatchNormalization(name = 'norm_layer')(merge_layer)\n",
        "    #Final output layer (classification whether the images are of the same label/person)\n",
        "    output_layer = Dense(1, activation=\"sigmoid\", name = 'output_layer')(normal_layer)\n",
        "    #Final model mapping\n",
        "    model = Model(inputs=[input_1, input_2], outputs = output_layer)\n",
        "    #Model compilation:\n",
        "    model.compile(optimizer = Adam(hp.Float('learning_rate', min_value = 1e-4,max_value = 1e-3,sampling = 'log')),loss = contrastive_loss(margin = 1))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_opt = kt.tuners.BayesianOptimization(model_building,\n",
        "                                           objective = 'loss',\n",
        "                                           max_trials = 10,\n",
        "                                           seed = random_seed)"
      ],
      "metadata": {
        "id": "CSGMTi1HBvuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_opt.search(train_tf,\n",
        "                 validation_data = valid_tf,\n",
        "                 epochs = 10,\n",
        "                 callbacks = [EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=2)])"
      ],
      "metadata": {
        "id": "zo59ZTSUFQqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e990401-67cc-4c10-a1e5-5078735f8316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "3                 |?                 |conv_blocks\n",
            "256               |?                 |filters_0\n",
            "avg               |?                 |pooling_0\n",
            "0.3               |?                 |dropout_0\n",
            "32                |?                 |filters_1\n",
            "avg               |?                 |pooling_1\n",
            "0.3               |?                 |dropout_1\n",
            "160               |?                 |filters_2\n",
            "max               |?                 |pooling_2\n",
            "0.2               |?                 |dropout_2\n",
            "70                |?                 |Dense units\n",
            "0.25              |?                 |dropout_final\n",
            "0.00046723        |?                 |learning_rate\n",
            "\n",
            "Epoch 1/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hypers = bayes_opt.get_best_hyperparameters(num_trials=1)[0]\n",
        "display(best_hypers.values)"
      ],
      "metadata": {
        "id": "b7_iyRAcMnZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = bayes_opt.hypermodel.build(best_hypers)"
      ],
      "metadata": {
        "id": "oVwLrQt1MnVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visual Keras\n",
        "visualkeras.layered_view(final_model, legend=True)"
      ],
      "metadata": {
        "id": "jjJX5G_mVqQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keras Model Plot\n",
        "tf.keras.utils.plot_model(final_model, show_shapes = True, show_layer_activations=True,\n",
        "                          show_layer_names = True, expand_nested = True)"
      ],
      "metadata": {
        "id": "sPsKOwQ_VqNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.summary()"
      ],
      "metadata": {
        "id": "pj8FUdnfVqKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = final_model.fit(train_tf,\n",
        "                          epochs = 5, verbose = 1,\n",
        "                          validation_data = valid_tf,\n",
        "                          callbacks = [EarlyStopping(patience = 2)])"
      ],
      "metadata": {
        "id": "ETencscCxDqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PN.plot_val_train_loss(history)"
      ],
      "metadata": {
        "id": "MjfYVXiwJkJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_thres = PN.opt_threshold(final_model, train_tf, train_labels)\n",
        "valid_thres = PN.opt_threshold(final_model, valid_tf, valid_labels)"
      ],
      "metadata": {
        "id": "gUg2qS7oJxgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'training optimal thresold {train_thres}')\n",
        "print(f'validation optimal thresold {valid_thres}')"
      ],
      "metadata": {
        "id": "0S2-SHpmKDB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_1 = PN.make_predictions(final_model, test_tf, train_thres)\n",
        "test_predictions_2 = PN.make_predictions(final_model, test_tf, valid_thres)"
      ],
      "metadata": {
        "id": "ijXzRpHWKOgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy_1 = PN.make_evaluation(test_labels, test_predictions_1, 'accuracy')\n",
        "test_accuracy_2 = PN.make_evaluation(test_labels, test_predictions_2, 'accuracy')"
      ],
      "metadata": {
        "id": "pJvDdgVWKdlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'accuracy score on test set using optimal threshold from training set: {test_accuracy_1}')\n",
        "print(f'accuracy score on test set using optimal threshold from validation set: {test_accuracy_2}')"
      ],
      "metadata": {
        "id": "-ae8HShyKqXS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "VSE_ML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "cf7e70c757e4f60095653c44545a762e49c6e5d3353dc968e17e829e1045004e"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}